<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Process Management in OS</title>
    <link rel="stylesheet" href="../../../../public/style.css">
    <style>
        body {
            background: #0f0c29;
            /* fallback for old browsers */
            background: -webkit-linear-gradient(to right, #24243e, #302b63, #0f0c29);
            /* Chrome 10-25, Safari 5.1-6 */
            background: linear-gradient(to right, #24243e, #302b63, #0f0c29);
            /* W3C, IE 10+/ Edge, Firefox 16+, Chrome 26+, Opera 12+, Safari 7+ */
            color: white;
        }
    </style>
</head>

<body>
    <div id="mySidepanel" class="sidepanel">
        <a href="javascript:void(0)" class="closebtn" onclick="closeNav()">×</a>
        <a href="../index.html" class="home">Home</a>
        <a href="#" class="link"></a>
    </div>
    <div id="navbar" class="grad">
        <div>
            <div class="openbtn" onclick="openNav()">
                <div id="nav-icon1" for="nav-menu1">
                    <span></span>
                    <span></span>
                    <span></span>
                </div>
            </div>
        </div>
        <div>
            <h2>Process Management in OS</h2>
        </div>
    </div>
    <div class="content-box">
        <h1>Process Management in OS</h1>
        <ul>
            <li>A program does nothing unless its instructions are executed by CPU.</li>
            <li>A program in execution is called a process.</li>
            <li>In order to accomplish its task, process needs the computer resources.</li>
            <li>There may exist more than one process in the system which may require the same resource at the same
                time. Therefore, the operating system has to manage all the processes and the resources in a convenient
                and efficient way.</li>
            <li>Some resources may need to be executed by one process at one time to maintain the consistency otherwise
                the system can become inconsistent, and deadlock may occur.
                <ul>
                    <li>A deadlock occurs when two or more processes are unable to proceed because they are waiting for
                        each other to release resources.</li>
                </ul>
            </li>
            <li>The operating system is responsible for the following activities in connection with Process Management:
                <ol>
                    <li>Scheduling procees and threads on the CPU's.</li>
                    <li>Creating and deleting both user and system processes.</li>
                    <li>Suspending and resuming processes.</li>
                    <li>Providing mechanisms for process synchronization.</li>
                    <li>Providing mechanisms for process communication.</li>
                </ol>
            </li>
        </ul>
        <div class="wh">
            <h2>What is process?</h2>
            <ul>
                <li>A process is a <u>program in execution</u> including the current values of the program counter,
                    registers and variables.</li>
                <li>The difference between a process and a program is that the program is the group of instruction where
                    as the process is the activity. Or we can say process is an active state of program.</li>
                <li>We write our computer programs in a text file and when we execute this program, it becomes a process
                    which performs all the tasks mentioned in the program.</li>
                <li>When a program is loaded into the memory and it becomes a process, it can be divided into four
                    sections: stack, heap, text and data.</li>
                <li>A process generally also includes the process stack, which contains temporary data (such as function
                    parameters, return addresses, and local variables), and a data section, which contains global
                    variables.</li>
            </ul>
            <img src="../../images/process1.svg" alt="" class="wb">
            <ul>
                <li>Stack: The process stack contains the temporary data such as method/function, parameters, return
                    address and local variables.</li>
                <li>Heap: This is dynamically allocated memory to a process during its runtim.</li>
                <li>Text: Program counters (It stores the list of address of next instructions that has to be executed
                    after the current process) & content of processor registers.</li>
                <li>Data: This section contains the all global and static variables.</li>
            </ul>
        </div>
        <div class="wh">
            <h2>Process States</h2>
            <ul>
                <li>When a process executes, it passes through different states.</li>
                <li>These stages may differ in different operating systems.</li>
                <li>In general, a process can have one of the following five states at a time.</li>
            </ul>
            <img src="../../images/process2.svg" alt="" class="wb">
            <ul>
                <li><b>New:</b> This is the initial state when a process is first started/created.</li>
                <li><b>Ready:</b> The process are waiting to have the processor allocated to them by the operating
                    system so that they can run.
                    <ul>
                        <li>Process may comein to this state after <i>Start</i> state or while running it by but
                            interrupted by the scheduler to assign CPU to some other process.</li>
                    </ul>
                </li>
                <li><b>Running</b>: After <i>Ready</i> state, the process state is set to running and the processor
                    execute its instruction.</li>
                <li><b>Waiting:</b> Process moves into the waiting state if it needs to wait for a resource, such as
                    waiting for user input, or waiting for a file to become available.</li>
                <li><b>Terminated:</b> Once the process finishes its execution or its is terminated by the operating
                    system, it is moved to the terminated state where it waits to be removed from main memory.</li>
            </ul>
            <div class="in">
                <h3>Attributes of a process</h3>
                <ul>
                    <li>The attributes of the process are used by the operating system to create the process control
                        block (PCB) for each of them.</li>
                    <li>This is also called context of the process. Attributes which are stored in the PCB are described
                        below.
                        <ol>
                            <li><b>Process ID</b>: When a process is created, a unique id is assigned to the process
                                which is used for unique identification of the process in the system.</li>
                            <li><b>Program counter</b>: A program counter stores the address of the last instruction of
                                the process on which the process was suspended. The CPU uses this address when the
                                execution of this process is resumed.</li>
                            <li><b>Process State</b>: The process, from its creation to the complemention, goes through
                                various states which are new, ready, running and waiting.</li>
                            <li><b>Priority</b>: Every process has its own priority. The process with the highest
                                priority among the process gets the CPU first. This is also stored on the process
                                control block.</li>
                            <li><b>General Purpose Registers</b>: Every process has its own set of registers which are
                                used to hold the data which is generated during the execution of the process.</li>
                            <li><b>List of open files</b>: During the execution, every process uses some files which
                                need to be present in the main memory. OS also maintains a list of open files in the
                                PCB.</li>
                            <li><b>List of open devices</b>: OS also maintain the list of all open devices which are
                                used during the execution of the process.</li>
                        </ol>
                    </li>
                </ul>
                <img src="../../images/manage1.svg" alt="" class="wb">
            </div>
        </div>
        <div class="wh">
            <h2>Process Scheduling</h2>
            <ul>
                <li>Operating system uses various schedulers for the process scheduling described below.</li>
            </ul>
            <div class="in">
                <h3>Long term scheduler</h3>
                <ul>
                    <li>Long term scheduler is also knwon as job scheduler. It chooses the process from the pool
                        (secondary memory) and keeps them in the ready queue maintained in the primary memory.</li>
                    <li>Long term schedular mainly controls the degree of multiprogramming. The purpose of long term
                        scheduler is to choose a perfect mix of IO bound and CPU bound processes among the process
                        present in the pool.</li>
                    <li>If the job scheduler chooses more IO bound processes, then all the process may reside in the
                        blocked state all the time and the CPU will remain idle most of the time. This will reduce the
                        degree of multiprogramming. Therefore, the job of long term scheduler is very critical and may
                        affect the system for a very long time.</li>
                </ul>
            </div>
            <div class="in">
                <h3>Process Queues</h3>
                <ul>
                    <li>The operating system manages various types of queues for each of the process states. </li>
                    <li>The PCB related to the process is also stored in the queue of the same state.</li>
                    <li>If the process is moved from one state to another state then its PCB is also unlinked from the
                        corresponding queue and added to the other state queue in which the transition is made.</li>
                </ul>
                <img src="../../images/manage2.svg" alt="" class="wb">
                <ol>
                    <li><b>Job Queue</b>
                        <ul>
                            <li>In starting, all the process get stored in the job queue.</li>
                            <li>It is maintained in the secondary memory.</li>
                            <li>The long term scheduler (Job scheduler) picks some of the process and put them in the
                                primary memory.</li>
                        </ul>
                    </li>
                    <li><b>Ready Queue</b>
                        <ul>
                            <li>Ready queue is maintained in primary memory.</li>
                            <li>The short term scheduler picks the job from the ready queue and dispatch of the CPU for
                                the execution.</li>
                        </ul>
                    </li>
                    <li><b>Waiting Queue</b>
                        <ul>
                            <li>When the process needs some IO operation in order to complete its execution, OS Changes
                                the state of the process from running to waiting.</li>
                            <li>The context (PCB) associated with the process gets stored on the waiting queue which
                                will be used by the processor when the process finishes the IO.</li>
                        </ul>
                    </li>
                </ol>
            </div>
            <div class="wh">
                <h2>Various Times related to Process:</h2>
                <img src="../../images/manage3.svg" alt="" class="wb">
                <ol>
                    <li><b>Arrival Time</b>
                        <ul>
                            <li>The time at which the process enters into the ready queue.</li>
                        </ul>
                    </li>
                    <li><b>Burst Time</b>
                        <ul>
                            <li>The total amount of time required by the CPU to execute the whole process is called the
                                Burst Time.</li>
                            <li>This does not include the waiting time.</li>
                            <li>It is confusing to calculate the execution time for a process even before executing it
                                hence the scheduling problems based on the burst time cannot be implemented in reality.
                            </li>
                        </ul>
                    </li>
                    <li><b>Completion Time</b>
                        <ul>
                            <li>The time at which the process enters into the completion state or the time at which the
                                process completes its execution.</li>
                        </ul>
                    </li>
                    <li><b>Turn around time</b>
                        <ul>
                            <li>The total amount of time spent by the process from its arrival to its completion.</li>
                        </ul>
                    </li>
                    <li><b>Waiting Time</b>
                        <ul>
                            <li>The total amount of time for which the process waits for the CPU to be assigned.</li>
                        </ul>
                    </li>
                    <li><b>Response Time</b>
                        <ul>
                            <li>The difference between the arrival time and the time at which the process first gets the
                                CPU.</li>
                        </ul>
                    </li>
                </ol>
            </div>
        </div>
        <div class="wh">
            <h2>CPU Scheduling</h2>
            <ul>
                <li><b>In the uniprogramming systems</b> like MS DOS, when a process waits for I/O operation to be done,
                    the CPU remains idol.
                    <ul>
                        <li>Uniprogramming is a type of operating system in which only one program can be executed at a
                            time.</li>
                    </ul>
                </li>
                <li>This is an overhead since it wastes the time and causes the problem of starvation.
                    <ul>
                        <li> "overhead" refers to the extra resources that are required by the system to perform tasks
                            beyond what is required for the user's program. Overhead can include the time, memory,
                            processing power, or other system resources that are needed to manage and run the operating
                            system itself.</li>
                    </ul>
                </li>
                <li>However, in <b>multirogramming systems</b>, the CPU doesn't remain idle during the waiting time of
                    the process and it starts executing other processes.</li>
                <li>Operating system has to define which process the CPU will be given.</li>
                <li><b>In multiprogramming systems</b>, the OS schedules the processes on the CPU to have the maximum
                    utilization of it and this procedure is called <b>CPU scheduling</b>. The Operating system uses
                    various scheduling algorithm to schedule the processes.</li>
                <li>This is a task of the short term schedular to schedule the CPU for the number of processes present
                    in the job pool.</li>
                <li>Whenever the running process requests some IO operation then the short term scheduler saves the
                    current context of the process (also called PCB) and changes its state from running to waiting.
                    During the time, process is in waiting state; the short term shceduler picks another process from
                    the ready queue and assigns the CPU to this process. This procedure is called <b>context
                        switching.</b></li>
            </ul>
            <div class="in">
                <h3>What is saved in the Process Control Block?</h3>
                <ul>
                    <li>The OS maintains a process control block during the lifetime of the process.</li>
                    <li>The process control block is deleted when the process is terminated or killed.</li>
                    <li>There is the following information which is saved in the PCB and is changing with the state of
                        the process.
                        <ol>
                            <li>Process ID &rarr; A unique identifier for the process.</li>
                            <li>Process State &rarr; The current state of the process (running, waiting, etc.)</li>
                            <li>Pointer &rarr; Pointers to the PCBs of the parent and child processes, and other
                                relevant data structures.</li>
                            <li>Priority &rarr; The priority of the process in relation to other processes in the
                                system.</li>
                            <li>Program Counter &rarr; The address of the next instruction to be executed.</li>
                            <li>CPU Registers &rarr; The values of the CPU registers for the process.</li>
                            <li>I/O status information &rarr; Information about the process's open files, pending I/O
                                requests, and other I/O-related data.</li>
                            <li>Accounting Information &rarr; The amount of CPU time used, clock time since process
                                creation, and other information used for process accounting.</li>
                            <li>etc.</li>
                        </ol>
                    </li>
                </ul>
            </div>
        </div>
        <div class="wh">
            <ul>
                <li>There are various algorithms which are used by the OS to schedule the processes on the processor in
                    an efficient way.</li>
            </ul>
            <p><b>The purpose of a Scheduling algorithm</b>
            <ol>
                <li>Maximum CPU utilization</li>
                <li>Fare allocation of CPU</li>
                <li>Maximum throughput</li>
                <li>Minimum turnaround time</li>
                <li>Minimum waiting time</li>
                <li>Minimum response time</li>
            </ol>
            </p>
            <p>There are the following algorithms which can be used to schedule the process.</p>
            <ol>
                <li>First Come First Serve</li>
                <li>Shortest Job First</li>
                <li>Round Robin</li>
            </ol>
        </div>
        <div class="wh">
            <h2>First Come First Server CPU Process Scheduling in OS</h2>
            <ul>
                <li>This is the basic algorithm which every student must learn to understand all the basics of CPU
                    Process Scheduling Algorithms.</li>
                <li>First Come First Serve paves the way for understanding of other algorithms.</li>
                <li>This algorithm may have many disadvantages, but these disadvantages created very new and
                    efficient algorithms. So, we should learn First Come First Serve first.</li>
                <li><b>Important Abbreviations:</b>
                    <ol>
                        <li>CPU &rarr; Central Processing Unit</li>
                        <li>FCFS &rarr; First Come First Serve</li>
                        <li>AT &rarr; Arrival Time</li>
                        <li>BT &rarr; Burst Time</li>
                        <li>WT &rarr; Waiting Time</li>
                        <li>TAT &rarr; Turn Around Time</li>
                        <li>CT &rarr; Completion Time</li>
                        <li>FIFO &rarr; First In First Out</li>
                    </ol>
                </li>
            </ul>
            <div class="in">
                <h3>First Come First Serve</h3>
                <ul>
                    <li>FCFS is the first algorithm of CPU process scheduling algorithm.</li>
                    <li>FCFS allow the process to execute in linear manner.</li>
                    <li>This means that whichever process enters the ready queue first is executed first.</li>
                    <li>This shows that FCFS algorithm follows FIFO principle.</li>
                    <li>The FCFS algorithm can be executed in Pre Emptive and Non Pre Emptive manner.</li>
                </ul>
            </div>
            <div class="in">
                <h3>Preemptive Approach</h3>
                <ul>
                    <li>Here the OS allots the resources to a process for a predetermined period of time.</li>
                    <li>The process transitions from running state to ready state or from waiting state to ready
                        state during resource allocation.</li>
                    <li>This switching happens because the CPU may assign other processes precedence and substitute
                        the currently active process for the higher priority process.</li>
                </ul>
            </div>
            <div class="in">
                <h3>Non Preemptive Approach</h3>
                <ul>
                    <li>Here the resource cannot be withdrawn from a process before the process has finished
                        running.</li>
                    <li>When a running process finishes and transitions to the waiting state, resources are
                        switched.</li>
                </ul>
            </div>
            <div class="in">
                <h3>Convoy Effect in FCFS</h3>
                <ul>

                    <li>Convoy effect is a phenomenon which occurs in the scheduling algorithm named FCFS.</li>
                    <li>The FCFS Scheduling algorithm occurs in a way of non preemptive way.</li>
                    <li>The non preemptive way means that if a process or job is started execution, then the
                        operating system must complete is process or job. </li>
                    <li>Until, the process is zero the next process does not start its execution.</li>
                    <li>The definition of Non Preemptive scheduling in terms of OS means that the CPU will be
                        completely dedicated till the end of the process started first and the new process is
                        executed only after finishing of the older process.</li>
                    <li>There may be a few cases, which might cause the CPU to allot a too much time. This is
                        because in the FCFS sheduling alorithm non preemptive approach, the process are chose in
                        serial oder. Due, to this shorter process behind the larger process takes too much time to
                        complete its execution. Due, to this the WT, TAT, CT is very high.</li>
                    <li>If the first process if large or completion time is too high, then convoy effect in the FCFS
                        algorithm is occured.</li>
                    <li>Let us assume that longer job takes infinite time to complete. Then, the remaining processes
                        have to wait for the same infinite time. Due to this convoy effect created by the longer job
                        the starvation of the waiting processes increases very rapidly. this is the biggest
                        disadvantage of FCFS CPU process scheduling.</li>
                </ul>
            </div>
            <div class="in">
                <h3>Characteristics of FCFS CPU Process Scheduling</h3>
                <ol>
                    <li>Implementation is simple.</li>
                    <li>Does not cause any casualties while using.</li>
                    <li>It adopts a no pre emptive and pre emptive strategy.</li>
                    <li>It runs each procedure in the order that they are recieved.</li>
                    <li>Arrival time is used as a selection criterin for procedures.</li>
                </ol>
            </div>
            <div class="in">
                <h3>Advantages of FCFS CPU Process Scheduling</h3>
                <ol>
                    <li>In order to allocate processes, it uses the FIFO queue.</li>
                    <li>The FCFS CPU Scheduling Process is straight forward and easy to implement.</li>
                    <li>In the FCFS situation pre emptive scheduling, there is not chance of process starving.</li>
                    <li>As there is no consideration of process priority, it is an equitable algorithm.</li>
                </ol>
            </div>
            <div class="in">
                <h3>Disadvantages of FCFS CPU Process Scheduling</h3>
                <ul>
                    <li>FCFS CPU Scheduling Algorithm has Long Waiting Time.</li>
                    <li>FCFS CPU Scheduling favors CPU over Input or Output operations.</li>
                    <li>In FCFS there is a chance of occurrence of Convoy Effect.</li>
                    <li>Because FCFS is so straight forward, it often isn't very effective. Extended waiting periods
                        go hand in hand with this. All other orders are left idle if the CPU is busy processing one
                        time-consuming order.</li>
                </ul>
            </div>
            <div class="in">
                <h3>Problems on the FCFS CPU Scheduling Algorithm</h3>
                <img src="../../images/numerical1.svg" alt="" class="wb">
                <p>This is how the FCFS is solved in Non Pre Emptive Approach.</p>
            </div>
        </div>
        <div class="wh">
            <h2>Shortest Job First (SJF) Scheduling</h2>
            <ul>
                <li>SJF Scheduling algorithm, schedules the processes according to their burst time.</li>
                <li>In SJF scheduling, the process with the lowest burst time, among the list of available processes in
                    the ready queue, is going to be scheduled next.</li>
                <li>However, it is very difficult to predict the burst time needed for a process hence this algorithm is
                    very difficult to implement in the system.</li>
            </ul>
            <div class="in">
                <h3>Advantages of SJF</h3>
                <ul>
                    <li>Maximum throughput</li>
                    <li>Minimum average waiting and turnaround time</li>

                </ul>
            </div>
            <div class="in">
                <h3>Disadvantages of SJF</h3>
                <ul>
                    <li>May suffer with the problem of starvation.</li>
                    <li>It is not implementable because the exact burst time for a process can't be known in advance.
                    </li>

                </ul>
            </div>
            <div class="in">
                <h3>Non-Preemptive shortest job first CPU Scheduling Algorithm example:</h3>
                <img src="../../images/numerical2.svg" alt="" class="wb">
                <ul>
                    <li><b>Advantages:</b>
                        <ul>
                            <li>SJF is better than the FCFS algorithm as it reduces the average waiting time.</li>
                            <li>SJF is genrally used for long term scheduling.</li>
                            <li>It is suitable for the jobs running in batches, where run times are already known.</li>
                            <li>SJF is probably optimal in terms of average turnaround time.</li>
                        </ul>
                    </li>
                    <li><b>Disadvantages:</b>
                        <ul>
                            <li>SJF may cause very long turn-around times or starvation.</li>
                            <li>In SJF job completion timme must be known earlier, but sometimes it is hard to predict.
                            </li>
                            <li>Sometimes, it is complicated to predict the length of the upcoming CPU request.</li>
                            <li>It leads to the starvation that does not reduce average turnaround time.</li>
                        </ul>
                    </li>
                </ul>
            </div>
            <div class="in">
                <h3>Preemptive SJF - Shortest Remaining Time First Scheduling Algorithm</h3>
                <ul>
                    <li>In SRTF schefuling algorithm, the process with the smallest amount of time remaining until
                        completion is selected to execute.</li>
                    <li>Since the currently executing process is the one with the shortest amount of time remaining by
                        definition, and since that time should only reduce as execution progresses, process will always
                        run until they complete or a new process is added that requires a smaller amount of time.</li>
                </ul>
                <p>Examples to show working of Preemptive Shortest Job First CPU Scheduling Algorithm &darr;</p>
                <img src="../../images/numerical3.svg" alt="" class="wb">
            </div>
        </div>
        <div class="wh">
            <h2>Round Robin Scheduling Algorithm</h2>
            <ul>
                <li>In RR algorithm each process is assigned a fixed time slot in a ciclic way.</li>
                <li>It is basically the preemptive version of FCFS scheduling algorithm.</li>
                <li>RR CPU algorithm generally focuses on Time sharing technique.</li>
                <li>The period of time for which a process or job is allowed to run in a pre-emptive method is called
                    time quantum.</li>
                <li>Each process present in the ready queue is assigned the CPU for that time quantum, if the execution
                    of the process is completed during that time then the process will end else the process will go back
                    to the waiting table and wait for its next turn to complete the execution.</li>
            </ul>
            <div class="in">
                <h3>Characteristics of RR:</h3>
                <ul>
                    <li>It is simle, easy to implement, and starvation-free as all process get fair share of CPU time.
                    </li>
                    <li>One of the most commonly used technique in CPU scheduling as a core.</li>
                    <li>It is preempitve as process are assigned CPU only for a fixed slice of time at most.</li>
                    <li>The disadvantages of it ismore overhead of context switching.</li>
                </ul>
            </div>
            <div class="in">
                <h3>Advantages of RR:</h3>
                <ul>
                    <li>There is fairness since every process gets equal share of CPU.</li>
                    <li>The newly created process is added to end of ready queue.</li>
                    <li>A round-robin scheduler generally employs time-sharing, giving each job a time slot
                        or quantum.</li>
                    <li>While performing a round-robin scheduling, a particular time quantum is allotted to
                        different jobs.</li>
                    <li>Each process get a chance to reschedule after a particular quantum time in this
                        scheduling</li>
                </ul>
            </div>
            <div class="in">
                <h3>Disadvantages of RR:</h3>
                <ul>
                    <li>There is Larger waiting time and Response time.</li>
                    <li>There is Low throughput</li>
                    <li>There is Context Switches</li>
                    <li>Gantt chart seems to come too big (if quantum time is less for scheduling.</li>
                    <li>Time consuming scheduling for small quantum</li>
                </ul>
            </div>
            <div class="in">
                <p><b>Consider the following table of arrival time and burst time for four processes P1, P2,
                        P3, and P4 and given Time Quantum = 2. &darr;</b></p>
                <img src="../../images/numerical4.svg" alt="" class="wb">
                <ul>
                    <li><a href="https://www.youtube.com/watch?v=6PEyXwdxeIc&t=557s" target="_blank">Helping video
                            &neArr;</a></li>
                </ul>
            </div>
        </div>
        <div class="wh">
            <h2>Multiple-Processor Scheduling</h2>
            <ul>
                <li>In multiple-processor scheduling multiple CPU's are available and hence <b>load sharing</b> becomes
                    possible.</li>
                <li>However multiple processor scheduling is more complex as compared to single processor scheduling.
                </li>
                <li>In multiple processor scheduling there are cases when the processors are identical i.e. HOMOGENEOUS,
                    in terms of their functionality, we can use any processor available to run any process in the queue.
                </li>
            </ul>
            <div class="in">
                <h3>Approaches to Multiple-Processor Scheduling:</h3>
                <ul>
                    <li>One approach is when all the scheduling decisions and I/O processing are handled by a single
                        processor which is called the <b>master server</b> and the other processors executes only the
                        <b>user code</b>. This is simple and reduces the need of data sharing. This entire scenario is
                        called <b>asymmetric multiprocessing.</b>
                    </li>
                    <li>A second approach uses <b>symmetric multiprocessing</b> where each processor is self scheduling.
                        All processes may be in common ready queue or each processor may have its own private queue for
                        ready processes. The scheduling proceeds further by having the scheduler for each processor
                        examine the ready queue and select a process to execute.</li>
                </ul>
            </div>
        </div>
        <div class="wh">
            <h2>Processor Affinity</h2>
            <ul>
                <li>Processor affinity is the ability to bind a process or thread to a specific CPU or core in a
                    multi-core system. This means that the process or thread will be scheduled to run exclusively on the
                    chosen CPU or core, and will not be allowed to run on any other CPU or core in the system.</li>
                <li>The purpose of processor affinity is to improve the performance of a system by reducing the overhead
                    of context switching between different CPUs or cores. By binding a process or thread to a specific
                    CPU or core, the operating system can reduce the time and resources needed to switch between
                    different CPUs or cores, which can result in faster execution times and more efficient use of system
                    resources.</li>
                <li>When a process runs on a specific processor there are certain effects on the cache memory. The
                    data most recently accessed by the process populate the cache for the processor and as a result
                    successive memory access by the process are often satisfied in the cache memory. Now if the
                    process migrates to another processor, the contents of the cache memory must be invalidated for
                    the first processor and the cache for the second processor must be repopulated. Because of the
                    high cost of invalidating and repopulating caches, most of the SMP(symmetric multiprocessing)
                    systems try to avoid migration of processes from one processor to another and try to keep a
                    process running on the same processor. This is known as PROCESSOR AFFINITY.</li>
            </ul>
            <div class="in">
                <h3>There are two types of processor affinity:</h3>
                <ol>
                    <li><b>Soft Affinity:</b> When an operating system has a policy of attempting to keep a process
                        running on the same processor but not guaranteering it will do so, this situation is called soft
                        affinity.</li>
                    <li><b>Hard Affinity:</b> Hard affinity allows a process to specify a subset of processors on which
                        it may run. Some systems such as Linux implements soft affinity but also provide some system
                        calls like <i>sched_setaffinity()</i> that supports hard affinity.</li>
                </ol>
            </div>
        </div>
        <div class="wh">
            <h2>Load Balancing</h2>
            <ul>
                <li>Load balancing is a phenomena which keeps the workload evenly distributed accross all processors in
                    a SMP system. Load balancing is necessary only on systems where each processors has its own private
                    queue of process which are eligible to execute.</li>
                <li>Load balancing is unncessary because once a processor becomes idle it immediately extracts a
                    runnable process from the common run queue.</li>
                <li>On SMP, it is important to keep the workload balanced among all processors to fully utilize the
                    benefits of having more than one processor else one or more processor will sit idle while other
                    processors have high workloads along with lists of processors awaiting the CPU.</li>
            </ul>
            <div class="in">
                <h3>There are two general approaches to load balancing:</h3>
                <ol>
                    <li><b>Push Migration:</b> In push migration a task routinely checks the load on each
                        processor and if it finds an imbalance then it evenly distributes load on each
                        processors by moving the processes from overloaded to idle or less busy processors.</li>
                    <li><b>Pull Migration:</b> Pull Migration occurs when an idle processor pulls a waiting task
                        from a busy processor for its execution.</li>
                </ol>
            </div>
        </div>
        <div class="wh">
            <h2>Multicore Processors</h2>
            <ul>
                <li>In multicore processors <b>multiple processor</b> core are placed on some physical chip.</li>
                <li>Each core has a register set to maintain its architectural state and thus appears to the operating
                    system as a separate physical processor.</li>
                <li><b>SMP systems</b> that use multicore processors are faster and consume less power than systems in
                    which each processor has its own physical chip.</li>
                <li>However multicore processors may complicate the scheduling problems.</li>
                <li>When processor accesses memory then it spends a significant amount of time waiting for the data to
                    become available, this situation is called <b>memory stall.</b> It occurs for various reasons such
                    as cache miss, which is accessing the data that is not in the cache memory. In such cases the
                    processor can spen upto fifty percent of its time waiting for data to become available from the
                    memory. To solve this problem recent hardware designs have implemented multithreaded processor cores
                    in which two or more hardware threads are assigned to each core. Therefor if one thread stalls while
                    waiting for the memory, core can switch to another thread.</li>
            </ul>
        </div>
        <div class="wh">
            <h2>Process and Thread</h2>
            <ul>
                <li><b>Process:</b>
                    <ol>
                        <li>Processes are basically the programs that are dispatched from the ready state and are
                            scheduled in the CPU for execution. PCB(Process Control Block) holds the concept of process.
                            A process can create other processes which are known as Child Processes. The process takes
                            more time to terminate and it is isolated means it does not share the memory with any other
                            process.</li>
                        <li>The process can have the following states: new, ready, running, waiting, terminated, and
                            suspended</li>
                    </ol>
                </li>
                <li><b>Thread:</b>
                    <ol>
                        <li>Thread is the segment of a process which means a process can have multiple threads
                            and these multiple threads are contained within a process. </li>
                        <li>A thread has three states: Running,
                            Ready, and Blocked.</li>
                        <li>The thread takes less time to terminate as compared to the process but unlike the process,
                            threads
                            do not isolate.</li>
                    </ol>
                </li>
            </ul>
            <div class="in">
                <h3>Difference between Process and Thread:</h3>
                <img src="../../images/thread1.svg" alt="" class="wb">
            </div>
        </div>
        <div class="wh">
            <h2>Multithreading in OS</h2>
            <ul>
                <li>Multithreading is a technique used in operating systems to enable multiple threads of execution
                    within a single process. A thread is a lightweight process that shares the same memory space and
                    resources as other threads in the same process. Multithreading allows for concurrent execution of
                    multiple tasks within a single process, making it possible to achieve better performance and
                    responsiveness in certain types of applications</li>
                <li>Lets say, for example a program is not capable of reading keystrokes while making drawings. These
                    tasks cannot be executed by the program at the same time. This problem can be solved through
                    multi-tasking so that two or more tasks can be executed simultaneously.</li>
                <li>One of the benefits of multithreading is that it can improve overall system responsiveness by
                    allowing applications to continue running even when some threads are blocked or waiting for I/O
                    operations to complete. Multithreading can also help to reduce the overhead associated with context
                    switching between processes, since switching between threads within a process is typically faster.
                </li>
                <li>The concept of multi-threading needs proper understanding of these two terms – a process and
                    a thread.
                    <ul>
                        <li> A process is a program being executed. A process can be further divided into
                            independent units known as threads.</li>
                        <li>A thread is like a small light-weight process within a process.
                            Or we can say a collection of threads is what is known as a
                            process.</li>
                    </ul>
                </li>
                <li>Multi-tasking is of two types:
                    <ol>
                        <li>Processor based: It is totally managed by the OS.</li>
                        <li>Thread based: It can be controlled by the programmer to some extent.</li>
                    </ol>
                </li>
            </ul>
            <img src="../../images/thread2.svg" alt="" class="wb">
            <div class="in">
                <h3>Applicaitons</h3>
                <p>Threading is a technique used in computer programming to improve the performance and responsiveness
                    of software applications. It involves dividing a program into multiple smaller threads or tasks that
                    can be executed independently and concurrently</p>
                <ul>
                    <li>Threading is used widely in almost every field.</li>
                    <li>Most widely it is seen over the internet nowadays where we are using transaction processing of
                        every type like reacharges, online transfer, banking etc.</li>
                    <li>GUI Applications: Threading is commonly used in Graphical User Interface (GUI) applications to
                        keep the interface responsive while performing computationally intensive tasks. For example,
                        when you click a button in a GUI application, a separate thread can be created to perform the
                        task while the main thread keeps the interface responsive.</li>
                    <li>Network Applications: Threading can be used in network applications to improve performance and
                        scalability. For example, a server application can use multiple threads to handle incoming
                        client connections simultaneously.</li>
                    <li>Multimedia Applications: Threading is commonly used in multimedia applications to play audio and
                        video files while simultaneously performing other tasks. For example, a media player can use a
                        separate thread to play the media file while the main thread handles user input and interface
                        updates.</li>
                    <li>Parallel Processing: Threading can be used in parallel processing applications to speed up
                        computations by dividing a large task into smaller independent tasks that can be executed
                        simultaneously on different threads.</li>
                    <li>Games: Threading can be used in games to keep the game running smoothly while performing tasks
                        such as physics calculations, artificial intelligence, and rendering</li>
                </ul>
            </div>
        </div>
    </div>
    <script src="../../../../public/main.js"></script>
</body>

</html>