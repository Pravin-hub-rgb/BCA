<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Unit 2</title>
    <link rel="stylesheet" href="../../../../public/style.css">
    <link rel="icon" href="../../../../public/logo/favicon_io/favicon.ico">
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>

<body class="bg-c">
    <div id="mySidepanel" class="sidepanel">
        <a href="javascript:void(0)" class="closebtn" onclick="closeNav()">×</a>
        <a href="../index.html" class="home">back</a>
        <div class="fix-column-links">
            <a href="#" class="link"></a>
            <div class="botbut">
                <a href="../unit3/index.html" class="link">Next Topic &rarr;</a>
                <a href="../unit1/index.html" class="link">&larr; Previous Topic</a>
            </div>
        </div>
    </div>
    <div id="navbar" class="grad">
        <div>
            <div class="openbtn" onclick="openNav()">
                <div id="nav-icon1" for="nav-menu1">
                    <span></span>
                    <span></span>
                    <span></span>
                </div>
            </div>
        </div>
        <div>
            <h2>Unit 2</h2>
        </div>
    </div>
    <div class="content-box">
        <div class="wh">
            <h2>Feed Forward Network</h2>
            <p>Feedforward neural networks (FNNs) are a class of artificial neural networks (ANNs) where the information
                moves in one direction—forward—from the input nodes, through the hidden layers, and finally to the
                output nodes. There are no cycles or loops in the network, which is why it's called "feedforward." This
                network structure is one of the simplest and most commonly used models in machine learning and deep
                learning for a variety of tasks such as classification, regression, and pattern recognition.</p>
            <p><strong>Key Components:</strong></p>
            <ol>
                <li>Input Layer: This layer receives the input data. The number of neurons in this layer corresponds to
                    the number of input features in the dataset.</li>
                <li>Hidden Layer(s): These layers are where computations take place using weights and activation
                    functions. A feedforward network can have one or more hidden layers, making it either a shallow or
                    deep neural network. The hidden layers are responsible for extracting and transforming features from
                    the input data.</li>
                <li>Output Layer: The final layer produces the network's output, which could be a class label (in
                    classification tasks) or a continuous value (in regression tasks). The number of neurons in the
                    output layer depends on the task, such as the number of classes for classification.</li>
                <li>Weights and Biases: Weights determine the influence of a particular input on the output, while
                    biases adjust the output along with the weighted sum of inputs, helping the network fit the data
                    better.</li>
                <li>Activation Functions: Activation functions (e.g., sigmoid, ReLU, or tanh) introduce non-linearity
                    into the network, enabling it to learn complex patterns.</li>
            </ol>
            <p><strong>Learning Process:</strong></p>
            <ul>
                <li>The training process of an FNN involves adjusting the weights and biases of the network to minimize
                    the error between the predicted and actual outputs. This is typically done using optimization
                    algorithms such as gradient descent, and the error is measured using a loss function (like mean
                    squared error for regression or cross-entropy for classification).</li>
                <li>Feedforward networks rely on the concept of supervised learning, where they are trained using
                    labeled datasets. During training, the network computes an output, compares it with the actual
                    label, and backpropagates the error through the network to update the weights in such a way that
                    future predictions become more accurate.</li>
            </ul>
            <p><strong>Variants of Feedforward Networks</strong></p>
            <p>There are several extensions of the basic feedforward network model, which enhance its functionality for
                specific tasks. Two popular variants are:</p>
            <ol>
                <li><strong>Back propagation Neural Network (BPN)</strong>: This is an extension of the feedforward
                    network that uses the back propagation algorithm to update the weights during the training process.
                    BPN is one of the most commonly used learning algorithms for feedforward networks, especially for
                    multi-layer perceptrons (MLPs). It minimizes the error by propagating it backward through the
                    network layers.</li>
                <li><strong>Radial Basis Function Network (RBFN)</strong>: RBFN is another variant of the feedforward
                    network, but it uses radial basis functions as activation functions. RBFNs are particularly useful
                    for interpolation problems, classification, and regression tasks. They consist of an input layer, a
                    hidden layer with radial basis function neurons, and an output layer, typically using linear
                    neurons.</li>
            </ol>
            <div class="in">
                <h3>Backpropagation Neural Network (BPN)</h3>
                <ul>
                    <li>It is a standard method for training Artificial Neural Networks (ANNs).</li>
                    <li>
                        BPN is a method of continuously adjusting the weights of the connections in the network to
                        minimize the difference between the actual output and the desired output. This method aims to
                        find the minimum value of the error in the weight space using the delta rule of gradient
                        descent.
                    </li>
                </ul>

                <p><strong>Steps in BPN:</strong></p>
                <ol>
                    <li>Input <strong>x</strong> is introduced to the network through pre-connected paths.</li>
                    <li>Inputs are modeled using randomly assigned weights <strong>w</strong>.</li>
                    <li>Calculate the output of each neuron, propagating from the input layer to the hidden layer, and
                        then to the output layer.</li>
                    <li>Calculate the error at the output layer. The error can be computed as the difference between the
                        actual output and the desired output (i.e., <strong>Error = Actual Output - Desired
                            Output</strong>).</li>
                    <li>
                        The error is then propagated backward, from the output layer to the hidden layer, and then back
                        to the input layer. The weights are adjusted at each layer to reduce the error. This process is
                        repeated iteratively until the error is minimized.
                    </li>
                </ol>
                <p><strong>Confusion?</strong></p>
                <ul>
                    <li>Even though backpropagation involves "going backward," this backward flow occurs only during the
                        training phase. The backpropagation algorithm computes the gradients of the error with respect
                        to each weight in the network by working backward, but this process is purely for adjusting the
                        weights and is not part of the actual inference or data flow during prediction.</li>
                    <li>Thus, during inference or the actual operation of the network (when you're making predictions),
                        the data still flows strictly in the forward direction—from inputs to outputs. This is why
                        networks trained using backpropagation are still considered feedforward networks. The term
                        "feedforward" refers to how information is processed when the network is used for predictions,
                        not how it learns.</li>
                    <li>BPN ko feedforward network ke under isliye include karte hain kyunki backward direction sirf
                        training ke time pe hota hai. Jab hum network ko train karte hain, tab error ko piche ki taraf
                        propagate karke weights adjust karte hain. Lekin jab actual prediction karte hain, yaani jab hum
                        model ko real data dete hain, toh data sirf forward direction mai flow hota hai—input se output
                        tak.
                        <br>
                        Yeh jo term 'feedforward' hai, yeh sirf prediction ke process ke baare mein hai, training ke
                        time pe kya hota hai, usse nahi. Isliye, BPN ko feedforward neural network mana jata hai, kyunki
                        prediction ke waqt data forward hi move karta hai.
                    </li>
                </ul>
                <div class="wh">
                    <p><strong>Example Problem:</strong> Assume that the neurons have a sigmoid activation function,
                        perform a forward pass and a backward pass on the network. Assume that the actual output of y is
                        0.5 and learning rate is 1.</p>
                    <img src="../../images/sc8.jpeg" alt="">
                    <p><strong>Forward Pass</strong>: Compute output for y<sub>3</sub>, y<sub>4</sub> and y<sub>5</sub>.
                    </p>
                    <ul>
                        <li>a<sub>j</sub> = \( \sum_{j} (w_ij * x_i) \)</li>
                        <br>y<sub>j</sub> = f(aj) = <span class="ms">\( f(x) = \frac{1}{1 + e^{-a_j}} \)</span>
                        <li>y<sub>3</sub> = f(a1) = <span class="ms">\( f(a1) = \frac{1}{1 + e^{-a_1}} \)</span>
                            <br>a1 = (w<sub>13</sub> * x<sub>1</sub> ) + (w<sub>23</sub> * x<sub>2</sub>) = 0.755
                            <br>y<sub>3</sub> = f(0.755) = <span class="ms">\( f(a1) = \frac{1}{1 + e^{-0.755}}
                                \)</span> = 0.68

                        </li>
                        <li>y<sub>4</sub> = f(a2) = <span class="ms">\( f(a2) = \frac{1}{1 + e^{-a_2}} \)</span>
                            <br>a2 = (w<sub>14</sub> * x<sub>1</sub> ) + (w<sub>24</sub> * x<sub>2</sub>) = 0.68
                            <br>y<sub>4</sub> = f(0.68) = <span class="ms">\( f(a1) = \frac{1}{1 + e^{-0.68}} \)</span>
                            = 0.6637

                        </li>
                        <li>y<sub>5</sub> = f(a3) = <span class="ms">\( f(a3) = \frac{1}{1 + e^{-a_1}} \)</span>
                            <br>a3 = (w<sub>35</sub> * y<sub>3</sub> ) + (w<sub>45</sub> * y<sub>4</sub>) = 0.801
                            <br>y<sub>5</sub> = f(0.801) = <span class="ms">\( f(a3) = \frac{1}{1 + e^{-0.801}}
                                \)</span> = 0.69

                        </li>
                        <li><strong>Error = y<sub>target</sub> - y<sub>5</sub> = -0.19</strong></li>
                    </ul>
                    <p>To get closure to the desired output we need to update the weight.</p>
                    <p><strong>Each Weight changed by:</strong></p>
                    <ul>
                        <li><span class="ms">&Delta;w<sub>ij</sub> = &eta;&delta;<sub>j</sub>O<sub>i</sub></span>
                            <ul>
                                <li>&delta;<sub>j</sub> = O<sub>j</sub>(1 - O<sub>j</sub>)(t<sub>j</sub> -
                                    O<sub>j</sub>) if <i>j</i> is an output unit</li>
                                <li>&delta;<sub>j</sub> = O<sub>j</sub>(1 - O<sub>j</sub>)\(
                                    \sum_{k}\)&delta;<sub>k</sub>w<sub>kj</sub> if <i>j</i> is a hidden unit</li>
                            </ul>
                        </li>
                        <li>where &eta; is a constant called the learning rate</li>
                        <li>t<sub>j</sub> is the correct output for unit j</li>
                        <li>&delta;<sub>j</sub> is the error measure for unit j</li>
                        <li>O<sub>i</sub> represents the output of the unit <i>i</i> in the previous layer. In the case
                            of a hidden or output unit, it refers to the activation value of that unit.</li>
                    </ul>

                    <p><strong>Backward Pass: Compute &delta;<sub>3</sub>, &delta;<sub>4</sub> and
                            &delta;<sub>5</sub></strong></p>
                    <img src="../../images/sc9.jpeg" alt="">
                    <ul>
                        <li>For output unit:
                            <br>&delta;<sub>5</sub> = y<sub>5</sub>(1-y<sub>5</sub>)(y<sub>target</sub> - y<sub>5</sub>)
                            <br> = 0.69*(1-0.69)*(0.5-0.69) = -0.0406
                        </li>
                        <li>For hidden unit:
                            <br>&delta;<sub>3</sub> = y<sub>3</sub>(1-y<sub>3</sub>)w35*&delta;<sub>5</sub>
                            <br>0.68*(1-0.68)*(0.3*(-0.0406)) = -0.00265
                        </li>
                        <li>For hidden unit:
                            <br>&delta;<sub>4</sub> = y<sub>4</sub>(1-y<sub>4</sub>)w45*&delta;<sub>5</sub>
                            <br>0.6637*(1-0.6637)*(0.9*(-0.0406)) = -0.0082
                        </li>
                    </ul>
                    <p><strong>Compute new weights</strong></p>
                    <p>&Delta;w<sub>ij</sub> = &eta;&delta;<sub>j</sub>O<sub>i</sub></p>
                    <ul>
                        <li>&Delta;w<sub>13</sub> = &eta;&Delta;<sub>3</sub>x<sub>1</sub> = 1 * (-0.00265) * 0.35 =
                            −0.0009275
                            <br>&Delta;w<sub>13</sub>(new) = &Delta;w<sub>13</sub> + w<sub>13</sub>(old) = −0.0009275 +
                            0.1 = 0.0991
                        </li>
                        <li>&Delta;w<sub>14</sub> = &eta;&Delta;<sub>4</sub>x<sub>1</sub> = 1 * (-0.0082) * 0.35 =
                            -0.00287
                            <br>&Delta;w<sub>14</sub>(new) = &Delta;w<sub>14</sub> + w<sub>14</sub>(old) = -0.00287 +
                            0.4 = 0.3971
                        </li>
                        <li>&Delta;w<sub>23</sub> = &eta;&Delta;<sub>3</sub>x<sub>2</sub> = 1 * (-0.00265) * 0.9 =
                            -0.002385
                            <br>&Delta;w<sub>23</sub>(new) = &Delta;w<sub>23</sub> + w<sub>23</sub>(old) = -0.002385 +
                            0.4 = 0.7976
                        </li>
                        <li>&Delta;w<sub>24</sub> = &eta;&Delta;<sub>4</sub>x<sub>2</sub> = 1 * (-0.0082) * 0.9 =
                            -0.00738
                            <br>&Delta;w<sub>24</sub>(new) = &Delta;w<sub>24</sub> + w<sub>24</sub>(old) = -0.00738 +
                            0.6 = 0.5926
                        </li>
                        <li>&Delta;w<sub>35</sub> = &eta;&Delta;<sub>5</sub>y<sub>3</sub> = 1 * (-0.0406) * 0.68 =
                            -0.0276
                            <br>&Delta;w<sub>35</sub>(new) = &Delta;w<sub>35</sub> + w<sub>35</sub>(old) = -0.0276 + 0.3
                            = 0.2724
                        </li>
                        <li>&Delta;w<sub>45</sub> = &eta;&Delta;<sub>5</sub>y<sub>4</sub> = 1 * (-0.0406) * 0.6637 =
                            -0.0269
                            <br>&Delta;w<sub>45</sub>(new) = &Delta;w<sub>45</sub> + w<sub>45</sub>(old) = -0.0269 + 0.9
                            = 0.8731
                        </li>
                    </ul>
                    <p><strong>Forward Pass: Compute output y<sub>3</sub>, y<sub>4</sub> and y<sub>5</sub>.</strong></p>
                    <img src="../../images/sc10.jpeg" alt="">
                    <ul>
                        <li>y<sub>3</sub> = f(a1) = <span class="ms">\( f(a1) = \frac{1}{1 + e^{-a_1}} \)</span>
                            <br>a1 = (w<sub>13</sub> * x<sub>1</sub> ) + (w<sub>23</sub> * x<sub>2</sub>) = 0.7525
                            <br>y<sub>3</sub> = f(0.7525) = <span class="ms">\( f(a1) = \frac{1}{1 + e^{-0.7525}}
                                \)</span> = 0.6797

                        </li>
                        <li>y<sub>4</sub> = f(a2) = <span class="ms">\( f(a2) = \frac{1}{1 + e^{-a_2}} \)</span>
                            <br>a2 = (w<sub>14</sub> * x<sub>1</sub> ) + (w<sub>24</sub> * x<sub>2</sub>) = 0.6797
                            <br>y<sub>4</sub> = f(0.6797) = <span class="ms">\( f(a1) = \frac{1}{1 + e^{-0.6797}}
                                \)</span>
                            = 0.6620

                        </li>
                        <li>y<sub>5</sub> = f(a3) = <span class="ms">\( f(a3) = \frac{1}{1 + e^{-a_1}} \)</span>
                            <br>a3 = (w<sub>35</sub> * y<sub>3</sub> ) + (w<sub>45</sub> * y<sub>4</sub>) = 0.7631
                            <br>y<sub>5</sub> = f(0.7631) = <span class="ms">\( f(a3) = \frac{1}{1 + e^{-0.7631}}
                                \)</span> = 0.6820 (Network Output)

                        </li>
                        <li><strong>Error = y<sub>target</sub> - y<sub>5</sub> = -0.182</strong></li>
                    </ul>
                </div>
            </div>
            <div class="in">
                <h3>Radial Basis Function Network (RBFN)</h3>
            
                <p><strong>What is an RBFN?</strong><br>
                    A <strong>Radial Basis Function Network (RBFN)</strong> is a type of artificial neural network that uses <strong>radial basis functions</strong>
                    (RBFs) to map input data into an output. It’s mainly used for <strong>classification</strong>, <strong>regression</strong>, and <strong>function approximation</strong>.
                    The network is especially useful for handling <strong>non-linear data</strong>, where relationships between the inputs and outputs are not
                    simple and straight-forward.
                </p>
            
                <h4>How Does an RBFN Work?</h4>
                <p>RBFNs have a simple but powerful design that works in three main layers. Let's break down each part:</p>
            
                <ul>
                    <li><strong>Three-Layer Structure:</strong>
                        RBFNs are built with three layers:
                        <ul>
                            <li><strong>Input Layer:</strong> The input layer receives the raw data (e.g., features or numbers).</li>
                            <li><strong>Hidden Layer:</strong> This is where the magic happens. The hidden layer neurons have specific "centers"
                                that measure how far the input data is from the center. This is done using a radial basis function (e.g., the <strong>Gaussian function</strong>).
                            </li>
                            <li><strong>Output Layer:</strong> This layer gives the final result. The weighted sum of the values from the hidden layer is passed here to produce the output.
                            </li>
                        </ul>
                    </li>
            
                    <li><strong>Using Distance for Classification:</strong>  
                        The key idea behind RBFNs is that each neuron in the hidden layer has a "center point." When new input comes in, the network calculates
                        how far the input is from these centers. The closer the input is to a center, the stronger the output signal. This helps the network 
                        classify or predict outputs based on these distances.
                    </li>
                </ul>
            
                <h4>Training an RBFN</h4>
                <p>Now that we know how the network is structured, let's talk about how the network learns and adjusts:</p>
            
                <ul>
                    <li><strong>Step 1: Find the Centers:</strong>
                        The centers of the hidden layer neurons are first chosen. This can be done using methods like <strong>k-means clustering</strong>, which groups similar inputs together and identifies the center of each group.
                    </li>
                    <li><strong>Step 2: Adjust the Weights:</strong>
                        After determining the centers, the network adjusts the <strong>weights</strong> between the hidden and output layers. These weights are fine-tuned using methods like <strong>gradient descent</strong> or <strong>least squares</strong>, helping the network learn how to make accurate predictions.
                    </li>
                </ul>
            
                <h4>Why Use RBFNs?</h4>
                <p>RBFNs are particularly useful for solving complex problems because of their ability to handle non-linear relationships. Here’s why they stand out:</p>
            
                <ul>
                    <li><strong>Handles Non-Linear Data:</strong> RBFNs are great for problems where the relationship between inputs and outputs isn't linear. They can transform complex, non-linear data into a form that is easier to model.</li>
                    <li><strong>Fast Training:</strong> RBFNs often train faster than other neural networks because the network only needs to adjust the weights between the hidden and output layers, not the centers.</li>
                    <li><strong>Good for Function Approximation:</strong> RBFNs are good at approximating unknown functions, making them ideal for tasks like time-series prediction, forecasting, and control systems.</li>
                </ul>
            
                <h4>Real-Life Example: Predicting House Prices</h4>
                <p>Let’s say you want to predict the price of a house based on features like location, size, and number of bedrooms.  
                    An RBFN works by calculating the distance between these input features and learned "center" points from similar houses, then
                    giving you a price prediction. It’s particularly good when the relationship between the features and the price isn’t simply linear, 
                    like if the price increases disproportionately with location or size.
                </p>
            </div>
            
        </div>
        <div class="wh">
            <h2>Feedback Neural Networks (Recurrent Neural Networks)</h2>
            <p>Feedback neural networks, also known as recurrent neural networks (RNNs), are a class of artificial
                neural networks where connections between the neurons form directed cycles, allowing information to be
                fed back into the network. Unlike feedforward networks where the information moves strictly in one
                direction, feedback networks allow for loops, meaning the network can retain information about previous
                inputs. This makes them suitable for tasks where the current output depends not only on the current
                input but also on past inputs, like sequence prediction, time-series forecasting, and language modeling.
            </p>
            <p><strong>Key Components:</strong></p>
            <ol>
                <li>Input Layer: The layer where the input data is received, similar to feedforward networks.</li>
                <li>Hidden Layers: These layers, like in feedforward networks, perform computations based on the input
                    data. However, in feedback networks, hidden layers often retain information about previous inputs,
                    enabling the network to learn from sequential patterns.</li>
                <li>Output Layer: This layer produces the final prediction or classification result. The number of
                    neurons depends on the task.</li>
                <li>Recurrent Connections: The hallmark of feedback networks is their recurrent connections, where
                    outputs of neurons can be fed back into themselves or previous layers. This feedback loop enables
                    the network to retain memory over time, a feature that's crucial for tasks like sequential data
                    processing.</li>
                <li>Weights and Biases: Similar to feedforward networks, feedback networks have weights and biases that
                    are adjusted during training to minimize the error between predicted and actual outputs.</li>
                <li>Activation Functions: These are used to introduce non-linearity into the network, which helps in
                    learning complex patterns.</li>
            </ol>
            <p><strong>Learning Process:</strong></p>
            <p>The training of feedback neural networks involves propagating the error back through time, which is done
                using algorithms such as Backpropagation Through Time (BPTT). Since the network has a memory of previous
                inputs, learning becomes more complex compared to feedforward networks. Feedback networks are capable of
                handling time-dependent data because they can learn from the temporal dependencies present in the input
                sequences.</p>
            <p><strong>Varianst of Feedback Networks</strong></p>
            <p>There are several important types of feedback networks that specialize in different tasks.
                <br>Two notable examples are:
            <ol>
                <li><strong>Hopfield Network</strong>: The Hopfield network is a type of recurrent neural network that
                    serves as a content-addressable memory system. It's designed for associative memory and pattern
                    recognition tasks. Each neuron in a Hopfield network is connected to every other neuron, forming a
                    fully connected network. Once trained, the network can retrieve a stored pattern even from partial
                    or noisy inputs.</li>
                <li><strong>Bidirectional Associative Memory (BAM)</strong>: BAM is another type of recurrent neural
                    network that is used for pattern recognition and associative memory. It can store pairs of patterns
                    (input-output pairs), and given one part of the pair, it can retrieve the other. Unlike the Hopfield
                    network, BAM works bidirectionally, meaning it can retrieve an output from a given input and vice
                    versa. It's often used for applications requiring associative recall.</li>
            </ol>
            </p>
            <div class="in">
                <h3>Hopfield Network</h3>
            
                <p>The <strong>Hopfield Network</strong> is a type of neural network used for remembering patterns and
                    retrieving them when given incomplete or noisy information. Think of it like your brain recognizing
                    a friend’s face even if they’re wearing sunglasses or a hat.</p>
            
                <h4>Key Concepts:</h4>
            
                <ul>
                    <li>
                        <strong>Neurons and States:</strong>
                        The Hopfield network is made up of simple units called <em>neurons</em>. Each neuron can have
                        only two states: <strong>on</strong> or <strong>off</strong> (typically represented as
                        <code>+1</code> and <code>-1</code>).
                    </li>
                    <li>
                        <strong>Connections Between Neurons:</strong>
                        Every neuron is connected to every other neuron, but <em>not to itself</em>. These connections
                        have <em>weights</em>, which decide how strongly one neuron influences another.
                    </li>
                    <li>
                        <strong>Pattern Storage:</strong>
                        The Hopfield network can store patterns (like pictures, sounds, or any data). Once it learns a
                        pattern, it can recall it from partial or distorted input. For example, if the network is
                        trained to remember a face, it can still recognize it even if the face is blurry.
                    </li>
                    <li>
                        <strong>How the Network Works:</strong>
                        <ul>
                            <li>
                                <strong>Learning:</strong> The Hopfield network learns by adjusting the weights between
                                neurons based on the patterns you give it. This process ensures that the network can
                                later recall these patterns.
                            </li>
                            <li>
                                <strong>Recall:</strong> When you give the network a part of a pattern (like a blurry
                                version of a face), it updates the neuron states until it matches the closest pattern it
                                remembers. This process happens in small steps, one neuron at a time.
                            </li>
                        </ul>
                    </li>
                    <li>
                        <strong>Stable States:</strong>
                        A Hopfield network has special stable states, called <em>attractors</em>. Once the network
                        reaches a stable state, it stops changing. These stable states correspond to the patterns it has
                        learned.
                    </li>
                    <li>
                        <strong>Energy Minimization:</strong>
                        Hopfield networks work by trying to minimize an "energy" function. This means the network always
                        moves towards a more stable pattern, just like a ball rolling downhill until it reaches the
                        bottom.
                    </li>
                </ul>
            
                <h4>Why Use Hopfield Networks?</h4>
            
                <ul>
                    <li>They are great for <strong>associative memory</strong>, where you want to remember something
                        based on partial input.</li>
                    <li>They’re used in <strong>pattern recognition</strong>, such as recognizing handwriting, faces, or
                        other types of data.</li>
                </ul>
            
                <h4>Real-World Example</h4>
            
                <p>Imagine you give a Hopfield network a picture of a cat to remember. Later, you give it a blurry or
                    incomplete version of the cat, and the network will fill in the missing details to recall the full
                    image.</p>
            
            </div>
            
            <div class="in">
                <h3>Bidirectional Associative Memory (BAM)</h3>
            
                <p><strong>Bidirectional Associative Memory (BAM)</strong> is a type of neural network that links two sets of patterns together, so you can recall one pattern if you know the other. It works by associating pairs of patterns, and it can retrieve one pattern from either side of the pair. This makes it useful for situations where two different patterns are connected, like matching translations between two languages or linking two related items.</p>
            
                <h4>Key Concepts</h4>
            
                <ul>
                    <li><strong>Bipolar Neurons:</strong> BAM uses neurons that can only have two possible states: <code>+1</code> (on) or <code>-1</code> (off). These simple states are used to represent the presence or absence of a particular pattern.</li>
                    <li><strong>Two Layers:</strong> BAM has two separate layers of neurons, which are the X layer and the Y layer. Each layer contains a pattern, and the neurons in the X layer are connected to neurons in the Y layer. These layers are designed to hold different patterns that are related to each other.</li>
                    <li><strong>Bidirectional Recall:</strong> BAM is special because it can recall the corresponding pattern from the opposite layer. For example, if you input a pattern into the X layer, BAM will find the matching pattern in the Y layer. Similarly, if you provide a pattern to the Y layer, BAM can recall the matching pattern from the X layer. This bidirectional linking is key to BAM’s functionality.</li>
                </ul>
            
                <h4>How BAM Works</h4>
            
                <ul>
                    <li><strong>Learning Process:</strong> BAM learns by adjusting the strength of connections between the neurons in the X and Y layers. When BAM is given a pair of patterns, one pattern in the X layer and the corresponding pattern in the Y layer, the network strengthens the connections between neurons that represent these patterns. This enables BAM to recall the patterns later when given part of either pattern.</li>
                    <li><strong>Recall Process:</strong> Once BAM has learned the associations between the patterns, it can recall the complete pattern if given an incomplete or partial input. For example, if you input part of the pattern from the X layer, BAM will use its learned connections to retrieve the corresponding pattern from the Y layer, and vice versa. This is done through a process of updating the states of the neurons until the most likely matching pattern is found.</li>
                </ul>
            
                <h4>Why Use BAM?</h4>
            
                <ul>
                    <li>BAM is great for <strong>pattern association</strong>, where you need to link two sets of patterns together. For example, in machine translation, BAM can associate words in one language with their equivalent words in another language.</li>
                    <li>It’s also useful in applications where data comes in pairs and needs to be recalled together, such as in <strong>image recognition</strong> or <strong>data retrieval systems</strong> where knowing one piece of information helps you retrieve the other.</li>
                </ul>
            
                <h4>Real-World Example</h4>
            
                <p>Imagine you train BAM to link English words with their French translations. If you input the word "dog" into the X layer, BAM will recall the French word "chien" in the Y layer. On the other hand, if you input "chien" into the Y layer, BAM will recall "dog" in the X layer. This bidirectional recall makes BAM useful for language translation tasks where you need to recall one translation after knowing the other.</p>
            
            </div>
            
        </div>
        <div class="wh">
            <h2>Self-Organizing Feature Maps (SOFM)</h2>
            <ul>
                <li>SOFMs, also called Kohonen networks, are a type of artificial neural network. Think of them like a
                    tool that helps organize and make sense of complicated data. What makes SOFMs special is that they
                    don’t need labels to learn. Instead, they figure things out on their own by studying patterns in the
                    data.</li>
                <li>Here’s what they do:
                    <ul>
                        <li>Make the data simpler: They take high-dimensional data (data with lots of features) and turn
                            it into something easier to look at—usually a 2D map.</li>
                        <li>Keep similar things together: If two pieces of data are alike, SOFMs make sure they are
                            placed close to each other on the map.</li>
                    </ul>
                </li>
                <li>They’re especially useful for:
                    <ul>
                        <li>Clustering: Grouping similar items together.</li>
                        <li>Visualization: Making it easier to see patterns in the data.</li>
                        <li>Dimensionality reduction: Shrinking large, complex data into a simpler form while keeping
                            its essence.</li>
                    </ul>
                </li>
                <li>A cool feature of SOFMs is that they preserve the "shape" of the data. Imagine spreading dots on a
                    sheet of paper in a way that clusters of similar dots stay close together. This is what SOFMs
                    do—they map the data in a way that keeps the original relationships intact.</li>
            </ul>
            <p><strong>Learning Process:</strong></p>
            <p>
                The learning process of a Self-Organizing Feature Map (SOFM) begins by setting up the network with
                random weights. Think of these weights as "guesses" that the network makes about how to match the input
                data.
                <br>When an input is given to the network, it identifies the <strong>Best Matching Unit (BMU)</strong>.
                The BMU is like the closest match or "best fit" among all the network's guesses for that input.
                <br>Next, the network updates the weights of the BMU and its nearby units to bring them closer to the
                input. This adjustment makes the network better at recognizing similar patterns in the future.
                <br>Over time, the learning rate (how much the weights change) and the neighborhood size (how many
                nearby units are adjusted) get smaller. This fine-tunes the network to improve accuracy.
                <br>SOFMs are useful because they can group similar data points together and show how data is related in
                a structured way. They are often used in tasks like recognizing patterns, grouping data, and finding
                important features in large datasets.
            </p>

            <p><strong>Variants of Self-Organizing Feature Maps:</strong></p>
            <p>There are several variations of SOFM, each designed for specific tasks. Here are two well-known ones:</p>
            <ol>
                <li>
                    <strong>Self-Organizing Maps (SOM):</strong> These are the most popular type of SOFM, created by
                    Teuvo Kohonen.
                    <br>Imagine SOM as a way to organize data into a two-dimensional grid while keeping related data
                    points close together. It's like arranging a messy pile of papers into neat rows based on their
                    content.
                    <br>SOMs are great for tasks like grouping similar data (clustering), recognizing patterns, and
                    simplifying complex data into a visual format that's easier to understand.
                </li>
                <li>
                    <strong>Learning Vector Quantization (LVQ):</strong> LVQ is a supervised learning method, meaning it
                    works with labeled data.
                    <br>Think of it as a combination of SOFM's ability to group data and the power to classify it into
                    specific categories.
                    <br>During training, LVQ adjusts its weight vectors to match the correct labels, improving its
                    ability to sort inputs into predefined classes. It's often used in situations where the goal is to
                    correctly label or categorize data.
                </li>
            </ol>

            <div class="in">
                <h3>Self-Organizing Maps (SOM)</h3>
            
                <p><strong>Self-Organizing Maps (SOM)</strong> are a type of neural network used for organizing and visualizing data without needing labels. They group similar data together, making it easier to understand patterns, especially in high-dimensional data. Think of it like sorting a pile of mixed items into categories based on their similarities, but without knowing what categories to expect in advance.</p>
            
                <h4>Key Concepts</h4>
            
                <ul>
                    <li><strong>Unsupervised Learning:</strong> SOM is an unsupervised learning algorithm, meaning it doesn't need labeled data. It learns by finding similarities in the input data and organizing them accordingly.</li>
                    <li><strong>Topological Map:</strong> The SOM creates a 2D map, where similar data points are placed close to each other, allowing you to see patterns in the data visually.</li>
                    <li><strong>Neurons and Grid:</strong> The network consists of a grid of neurons, each representing a group of similar data points. Each neuron adjusts its “weight” (value) to match the input data during training.</li>
                </ul>
            
                <h4>How SOM Works</h4>
            
                <ul>
                    <li><strong>Training:</strong> SOM is trained by presenting input data repeatedly. The neurons adjust their weights to better match the data. With each step, the neurons closest to the input data change more.</li>
                    <li><strong>Best Matching Unit (BMU):</strong> The neuron that is closest to the input data (based on its weight) is called the Best Matching Unit (BMU). This neuron and its neighbors adjust their weights to match the input better.</li>
                    <li><strong>Neighborhood Function:</strong> The adjustment happens not just at the BMU, but also in nearby neurons. Neurons that are closer to the BMU adjust more, helping to group similar data together in the map.</li>
                </ul>
            
                <h4>Why Use SOM?</h4>
            
                <ul>
                    <li><strong>Data Visualization:</strong> SOM is great for turning complex, high-dimensional data into a simple 2D map, making patterns easier to see.</li>
                    <li><strong>Clustering:</strong> It’s useful for clustering similar data points together, even when you don't know the groups in advance.</li>
                    <li><strong>Dimensionality Reduction:</strong> SOM reduces the complexity of data while maintaining its structure, making analysis easier.</li>
                </ul>
            
                <h4>Real-World Example</h4>
            
                <p>Imagine you have data on customers’ shopping habits, including information like age, income, and products bought. A SOM can group customers with similar behaviors together. After training, you can visualize these customer groups on a 2D map, where similar customers are close to each other, helping you find patterns and insights.</p>
            </div>
            
            <div class="in">
                <h3>Learning Vector Quantization (LVQ)</h3>
            
                <p><strong>Learning Vector Quantization (LVQ)</strong> is a supervised learning algorithm used for classification tasks. It groups data into categories using prototypes, which are reference points that represent different classes. When a new input comes in, LVQ finds the closest prototype and assigns it to the corresponding category.</p>
            
                <h4>Key Concepts</h4>
            
                <ul>
                    <li><strong>Supervised Learning:</strong> LVQ is supervised, meaning it learns from labeled data to classify new inputs into predefined categories.</li>
                    <li><strong>Prototypes:</strong> Prototypes are the reference points that represent classes in the data. They are adjusted during training to improve classification accuracy.</li>
                    <li><strong>Winner-Takes-All Rule:</strong> When an input is presented, the closest prototype (the "winner") is updated to better match the input, strengthening its class representation.</li>
                </ul>
            
                <h4>How LVQ Works</h4>
            
                <ul>
                    <li><strong>Initialization:</strong> Start with a set of prototypes representing the different classes in the training data.</li>
                    <li><strong>Training:</strong> The network presents input vectors, and the closest prototype is selected. Prototypes are adjusted based on whether they represent the correct class or not.</li>
                    <li><strong>Prototype Adjustment:</strong> Correct prototypes move closer to the input data, while incorrect prototypes move further away, reducing classification errors.</li>
                </ul>
            
                <h4>Why Use LVQ?</h4>
            
                <ul>
                    <li><strong>Simple and Interpretable:</strong> LVQ is easy to understand and visualize, as the classification boundaries are based on prototypes.</li>
                    <li><strong>Effective for Classification:</strong> It works well for problems where data can be clustered into clear categories.</li>
                    <li><strong>Versatile:</strong> LVQ can be applied to many types of classification tasks, like image recognition or medical diagnosis.</li>
                </ul>
            
                <h4>Real-World Example</h4>
            
                <p>Imagine classifying flowers based on features like petal length and width. LVQ would create prototypes for different flower types (e.g., roses, lilies). As the network learns, these prototypes adjust to better represent each flower type, enabling accurate classification of new flowers.</p>
            </div>
            
        </div>
    </div>
    <script type="module" src="../../../../public/main.js"></script>
</body>

</html>